{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RECnPlay-2019-Processamento-documentos-escaneados",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsaguiar/Extraindo-e-Estruturando-Dados-de-Documentos-Escaneados/blob/master/Processamento_documentos_escaneados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2iVnwsAaEt",
        "colab_type": "text"
      },
      "source": [
        "# RECnPlay 2019 - Processando documentos escaneados\n",
        "\n",
        "Por [Denys Farias](mailto:denys.lf@gmail.com) e [Rafael Aguiar](mailto:sextaa@gmail.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we1JPEp2BdU3",
        "colab_type": "text"
      },
      "source": [
        "# Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKbaLeXsTZ0U",
        "colab_type": "text"
      },
      "source": [
        "1. Converter um PDF de Cartão de Ponto em imagens;\n",
        "\n",
        "2. Extrair texto de imagens (OCR);\n",
        "\n",
        "3. Estruturar texto para obter batidas do cartão de ponto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRuxJUrRqnKx",
        "colab_type": "text"
      },
      "source": [
        "# Acompanhando o código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llMwnbb8qp58",
        "colab_type": "text"
      },
      "source": [
        "# https://www.codepile.net/pile/YwMNAx5Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk_J0P5X0qK5",
        "colab_type": "text"
      },
      "source": [
        "# Baixando o PDF de Exemplo\n",
        "\n",
        "https://drive.google.com/open?id=1B0K9Ea21_XDux1eLkP4_mfh6GQDoxZ7h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q4ddrYQlm_U",
        "colab_type": "text"
      },
      "source": [
        "# Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VMtzdguQLUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definindo a pasta /content como atual e limpando o conteúdo dela\n",
        "%cd /content\n",
        "%rm -rf *\n",
        "%ls\n",
        "\n",
        "\n",
        "# Instalando a biblioteca cliente do Google Cloud Vision (requer reinicialização)\n",
        "!pip install --upgrade google-cloud-vision\n",
        "\n",
        "\n",
        "# Instalando bibliotecas para manipulação de pdf\n",
        "!sudo apt install poppler-utils\n",
        "!pip install pdf2image\n",
        "\n",
        "\n",
        "# Instalando bibliotecas para plotar anotações no Google Colab\n",
        "!pip install mpld3\n",
        "!pip install \"git+https://github.com/javadba/mpld3@display_fix\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAb6MWlclypO",
        "colab_type": "text"
      },
      "source": [
        "# 1. Converter PDF em imagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qCHMO5wmRSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Carregar PDF\n",
        "uploaded_files = files.upload()\n",
        "filenames = list(uploaded_files.keys())\n",
        "pdf_filename = filenames[0]\n",
        "\n",
        "\n",
        "# Criar pasta para as imagens, se não houver\n",
        "images_folder = \"/content/pdf_images\"\n",
        "if not os.path.exists(images_folder):\n",
        "  try:\n",
        "    os.mkdir(images_folder)\n",
        "  except OSError:  \n",
        "    print (\"Creation of the directory %s failed\" % images_folder)\n",
        "  else:  \n",
        "    print (\"Successfully created the directory %s \" % images_folder)\n",
        "else:\n",
        "  print (\"Directory %s already exists\" % images_folder)\n",
        "\n",
        "\n",
        "# Converter PDF em imagens\n",
        "pdf_pages = convert_from_path(pdf_filename, dpi=200, output_folder=images_folder, fmt='png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk0LGmiddCqg",
        "colab_type": "text"
      },
      "source": [
        "# 2. Extrair texto das imagens (OCR) com o Google Cloud Vision API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWcOdLOSz3Mn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# https://cloud.google.com/vision/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMvC0eUcn0Dc",
        "colab_type": "text"
      },
      "source": [
        "## Detalhando a estrutura do retorno JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz1SIRKRfXME",
        "colab_type": "text"
      },
      "source": [
        "> *fullTextAnnotation é uma resposta hierárquica estruturada do texto extraído da imagem. Ele é organizado como Pages (páginas) → Blocks (blocos) → Paragraphs (parágrafos) → Words (palavras) → Symbols (símbolos):*\n",
        "\n",
        "> - *Page é um conjunto de blocos, além de metainformações sobre a página: tamanhos, resoluções (a X e a Y podem ser diferentes) etc.*\n",
        "\n",
        "> - *Block representa um elemento \"lógico\" da página. Por exemplo, uma área coberta por texto, uma imagem ou um separador entre colunas. Os blocos de texto e tabela contêm as principais informações necessárias para extrair o texto.*\n",
        "\n",
        "> - *Paragraph é uma unidade estrutural de texto que representa uma sequência ordenada de palavras. Por padrão, as palavras são separadas por quebras.*\n",
        "\n",
        "> - *Word é a menor unidade do texto. Ela é representada como um conjunto de símbolos.*\n",
        "\n",
        "> - *Symbol representa um caractere ou um sinal de pontuação.*\n",
        "\n",
        "> *fullTextAnnotation também fornece URLs para imagens da Web que correspondem em parte ou totalmente à imagem na solicitação.*\n",
        "\n",
        "Fonte: https://cloud.google.com/vision/docs/fulltext-annotations?hl=pt-br"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrBoLpzLeXKd",
        "colab_type": "text"
      },
      "source": [
        "## Como criar e gerenciar chaves de conta de serviço"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCc8DRIQZQON",
        "colab_type": "text"
      },
      "source": [
        "https://cloud.google.com/iam/docs/creating-managing-service-account-keys?hl=pt-br#iam-service-account-keys-create-console"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1WgGm-w3eFg",
        "colab_type": "text"
      },
      "source": [
        "## Credencial de testes para baixar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF-Cj7gw3jBF",
        "colab_type": "text"
      },
      "source": [
        "https://drive.google.com/open?id=1wQ28kdUYp9gT-rAWj8jJ-dn4DLiV6Atp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp0w5tvGpLAI",
        "colab_type": "text"
      },
      "source": [
        "## Importando e configurando as credenciais do Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yl2ZEa-ReaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "uploaded_credentials_filename = list(files.upload().keys())\n",
        "\n",
        "if uploaded_credentials_filename:\n",
        "  # Definir a variável de ambiente GOOGLE_APPLICATION_CREDENTIALS para o caminho do arquivo JSON \n",
        "  os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = uploaded_credentials_filename[0]\n",
        "\n",
        "  print(\"Credentials ready!\")\n",
        "\n",
        "else:\n",
        "  print(\"Credentials not ready.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpnnFW4lAguo",
        "colab_type": "text"
      },
      "source": [
        "## Carregando imagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22prN-FarRu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "from os import listdir\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "# The name of the image file to annotate\n",
        "image_path = f'{images_folder}/{listdir(images_folder)[0]}'\n",
        "\n",
        "# Loads the image into memory\n",
        "with io.open(image_path, 'rb') as image_file:\n",
        "    image_content = image_file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8r6UJzbHYuR",
        "colab_type": "text"
      },
      "source": [
        "## Utilizando a API do Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr_cY7-6ZfF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "\n",
        "client = vision.ImageAnnotatorClient()\n",
        "gc_image = types.Image(content=image_content)\n",
        "\n",
        "# Performs label detection on the image file\n",
        "gc_response = client.text_detection(image=gc_image)\n",
        "texts = gc_response.text_annotations\n",
        "\n",
        "print('Texts:')\n",
        "for text in texts:\n",
        "  print('\\n\"{}\"'.format(text.description))\n",
        "  for vertex in text.bounding_poly.vertices:\n",
        "    vertices = (['({},{})'.format(vertex.x, vertex.y)])\n",
        "    print('bounds: {}'.format(','.join(vertices)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt_D1B_5dLAw",
        "colab_type": "text"
      },
      "source": [
        "# 3. Estruturar texto em batidas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hmK7sL8sK4b",
        "colab_type": "text"
      },
      "source": [
        "## Considerações sobre o Bounding Box"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4jyv8tHU9tm",
        "colab_type": "text"
      },
      "source": [
        "> The bounding box for the block. The vertices are in the order of top-left, top-right, bottom-right, bottom-left. When a rotation of the bounding box is detected the rotation is represented as around the top-left corner as defined when the text is read in the 'natural' orientation. For example:\n",
        "\n",
        "> when the text is horizontal it might look like:\n",
        "```\n",
        "    0----1\n",
        "    |    |\n",
        "    3----2\n",
        "  ```\n",
        "  \n",
        "> when it's rotated 180 degrees around the top-left corner it becomes:\n",
        "```    \n",
        "    2----3\n",
        "    |    |\n",
        "    1----0\n",
        "```\n",
        "    \n",
        "> and the vertex order will still be (0, 1, 2, 3).\n",
        "\n",
        "Fonte: https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6COBjIeFINxt",
        "colab_type": "text"
      },
      "source": [
        "## Reunindo as palavras extraídas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13iFMyckA-yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "page = gc_response.full_text_annotation.pages[0]\n",
        "all_words = [word for block in page.blocks for paragraph in block.paragraphs for word in paragraph.words]\n",
        "\n",
        "all_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s_MxtMIaFrp",
        "colab_type": "text"
      },
      "source": [
        "## Definindo funções auxiliares para plotagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP9QAPMOXkn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mpld3\n",
        "from mpld3 import plugins\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from matplotlib.pyplot import figure\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "# Para preparar área de plotagem\n",
        "def prepare_image_data(image_data):\n",
        "\tim = np.array(image_data, dtype=np.uint8)\n",
        "\n",
        "\t# Create figure and axes\n",
        "\tfig,ax = plt.subplots(1)\n",
        "\t\n",
        "  # Adjust the \n",
        "\twidth = 15\n",
        "\theight = width * image_data.size[1] / image_data.size[0]\n",
        "\tfig.set_size_inches(width, int(height), forward=True)\n",
        "\t\n",
        "\tplugins.connect(fig, plugins.MousePosition(fontsize=14))\n",
        "\tmpld3.enable_notebook()\n",
        "  \n",
        "\t# Display the image\n",
        "\tax.imshow(im)\n",
        "\n",
        "\treturn ax\n",
        "\n",
        "\n",
        "# Para definir uma paleta de cores e visualizar melhor as anotações\n",
        "def get_tab10_color_from_index(color_index):\n",
        "\tCOLORS_COUNT = 10\n",
        "\tcmap = plt.cm.tab10\n",
        "\tcolor = cmap(color_index % COLORS_COUNT)\n",
        "\treturn color\n",
        "\n",
        "\n",
        "# Para plotar polígonos\n",
        "def plot_polygon(ax, vertices, color_index, to_fill = False):\n",
        "\tcolor = get_tab10_color_from_index(color_index)\n",
        "\tpoints_series = [[vertex.x,vertex.y] for vertex in vertices]\n",
        "\n",
        "\tpolygon = patches.Polygon(points_series,linewidth=1,edgecolor=color,fill=color if to_fill else None)\n",
        "\tax.add_patch(polygon)\n",
        "\n",
        "\n",
        "# Para anotar texto sobre a plotagem\n",
        "def annotate(text, vertex):\n",
        "\tplt.annotate(text, (vertex.x, vertex.y))\n",
        "\n",
        "\n",
        "# Para renderizar a plotagem\n",
        "plot = lambda: mpld3.display()\n",
        "\n",
        "\n",
        "# Para capturar texto de palavra\n",
        "def get_word_text(word):\n",
        "  return ''.join([symbol.text for symbol in word.symbols])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cOyGiOVjDbD",
        "colab_type": "text"
      },
      "source": [
        "## Plotando palavras encontradas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6D3LMwJjGGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_data = Image.open(image_path)\n",
        "\n",
        "ax = prepare_image_data(image_data)\n",
        "for\titem_index, word in enumerate(all_words):\n",
        "  plt.title(f'{image_path} words')\n",
        "  plot_polygon(ax, word.bounding_box.vertices, color_index= item_index, to_fill= False)\n",
        "  annotate(get_word_text(word), word.bounding_box.vertices[1])\n",
        "\n",
        "plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUA_kWGGUMB5",
        "colab_type": "text"
      },
      "source": [
        "## Definido código auxiliar para agrupar as palavras por linhas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5BZWb6USFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics\n",
        "import itertools\n",
        "\n",
        "# Ordenando palavras verticamente\n",
        "ordered_words = sorted(all_words, key=lambda word: word.bounding_box.vertices[0].y)\n",
        "\n",
        "\n",
        "# Para estimar alturar de palavras\n",
        "def get_height(word):\n",
        "  left_height = abs(word.bounding_box.vertices[0].y - word.bounding_box.vertices[3].y)\n",
        "  right_height = abs(word.bounding_box.vertices[1].y - word.bounding_box.vertices[2].y)\n",
        "  return (left_height + right_height) // 2\n",
        "\n",
        "\n",
        "# Para decidir se palavra é \"estável\", ou seja, possui menos variações no bounding box.\n",
        "min_stable_word_len = 3\n",
        "\n",
        "def is_stable(word):\n",
        "  return len(get_word_text(word)) >= min_stable_word_len\n",
        "\n",
        "\n",
        "# Para estimar referência de altura de palavras\n",
        "sample_size_for_height_reference_words = 5\n",
        "\n",
        "def get_word_reference_height(words):\n",
        "  # sample words for line height estimation\n",
        "  stable_words = (word for word in words if is_stable(word))\n",
        "  height_reference_words = list(itertools.islice(stable_words, sample_size_for_height_reference_words))\n",
        "\n",
        "  if not height_reference_words:\n",
        "    height_reference_words = [words[0]]\n",
        "  \n",
        "  # minimize variation on words heights\n",
        "  word_reference_height = statistics.median([get_height(height_reference_word) for height_reference_word in height_reference_words])\n",
        "  \n",
        "  return word_reference_height\n",
        "\n",
        "word_reference_height = get_word_reference_height(ordered_words)\n",
        "\n",
        "\n",
        "# Para estimar variação vertical entre palavras\n",
        "def get_accepted_y_variation(word_reference_height):\n",
        "  return (word_reference_height + 2) // 3\n",
        "\n",
        "accepted_y_variation = get_accepted_y_variation(word_reference_height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrht8XxsW2lb",
        "colab_type": "text"
      },
      "source": [
        "## Agrupando palavras filtradas em linhas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYKMmcuSJZ2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignorando palavras muito pequenas, que tendem a ser ruído\n",
        "no_small_ordered_words = [word for word in ordered_words if get_height(word) >= word_reference_height / 2]\n",
        "\n",
        "lines = {}\n",
        "lines[0] = []\n",
        "\n",
        "current_line_index = 0\n",
        "current_line_y = no_small_ordered_words[0].bounding_box.vertices[0].y\n",
        "\n",
        "for word in no_small_ordered_words:\n",
        "\n",
        "  current_y = word.bounding_box.vertices[0].y\n",
        "  is_new_line_by_y_variation = abs(current_y - current_line_y) > accepted_y_variation\n",
        "  \n",
        "  if is_new_line_by_y_variation:\n",
        "    \n",
        "    line_sorted_horizontally = sorted(lines[current_line_index], key=lambda word: word.bounding_box.vertices[0].x)\n",
        "    lines[current_line_index] = line_sorted_horizontally \n",
        "    \n",
        "    current_line_index += 1\n",
        "    lines[current_line_index] = []\n",
        "\n",
        "    # reference Y for a line should be estimated between neighboring stable words\n",
        "    is_long_enough_to_update_line_Y_reference = is_stable(word)\n",
        "    \n",
        "    if is_long_enough_to_update_line_Y_reference:\n",
        "      current_line_y = current_y\n",
        "\n",
        "  lines[current_line_index] = lines[current_line_index] + [word]\n",
        "  current_line_y = current_y\n",
        "\n",
        "\n",
        "# Exibindo texto das linhas\n",
        "lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgn1ByNy-U2g",
        "colab_type": "text"
      },
      "source": [
        "### Plotando as linhas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d24CUmLR-YfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = prepare_image_data(image_data)\n",
        "for\titem_index, words in lines.items():\n",
        "  for word in words:\n",
        "    plt.title(f'{image_path} lines')\n",
        "    plot_polygon(ax, word.bounding_box.vertices, color_index= item_index, to_fill= False)\n",
        "    annotate(get_word_text(word), word.bounding_box.vertices[2])\n",
        "\n",
        "plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHvckKrU-eVg",
        "colab_type": "text"
      },
      "source": [
        "## Preparando código para auxiliar na identificação de linhas com datas de batidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiKMOoMi-0RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Para limpar caracteres iniciais indesejados\n",
        "TOKENS_TO_STRIP = ['.', '-', '_', ':', '*', '\\'', '\"', '`', '´', '|', '~', '^', 'º', 'ª', '<', '>', '°', ';', '¨']\n",
        "\n",
        "def ltrip_words(words, tokens_to_strip = TOKENS_TO_STRIP):\n",
        "  result = list(words)\n",
        "  to_examine_beginning = any(words)\n",
        "  \n",
        "  while to_examine_beginning:\n",
        "    text_to_strip = get_word_text(result[0])\n",
        "    stripped_text = text_to_strip.lstrip(''.join(TOKENS_TO_STRIP))\n",
        "    \n",
        "    if stripped_text:\n",
        "      to_examine_beginning = False\n",
        "      continue\n",
        "\t\t\n",
        "    result = result[1:]\n",
        "    if not result:\n",
        "      break\n",
        "\t\n",
        "  return result\n",
        "\n",
        "\n",
        "# Para estimar vértices do bounding box de um conjunto de símbolos\n",
        "def estimate_word_vertices(symbols):\n",
        "\tif not symbols:\n",
        "\t\traise ValueError('Could not estimate from empty symbols.')\n",
        "    \n",
        "\tvertex_0 = symbols[0].bounding_box.vertices[0]\n",
        "\tvertex_1 = symbols[-1].bounding_box.vertices[1]\n",
        "\tvertex_2 = symbols[-1].bounding_box.vertices[2]\n",
        "\tvertex_3 = symbols[0].bounding_box.vertices[3]\n",
        "\n",
        "\treturn [vertex_0, vertex_1, vertex_2, vertex_3]\n",
        "\n",
        "\n",
        "# Para extrair uma data de uma linha\n",
        "leading_date_words_count = 6\n",
        "\n",
        "def extract_date(line_words):\n",
        "  \n",
        "  max_leading_date_words_count = min(len(line_words), leading_date_words_count)\n",
        "  \n",
        "  leading_words = line_words[:max_leading_date_words_count]\n",
        "  \n",
        "  leading_text = ''.join([get_word_text(word) for word in leading_words])\n",
        "  \n",
        "  match = re.search(r'\\d{2}/\\d{2}/\\d{4}', leading_text)\n",
        "\n",
        "  extracted_date = None\n",
        "  \n",
        "  if match:\n",
        "    extracted_pattern = match.group()\n",
        "    \n",
        "    try:\n",
        "      date_obj = datetime.datetime.strptime(extracted_pattern, '%d/%m/%Y')\n",
        "      extracted_date = extracted_pattern\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "  return extracted_date, leading_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD2_FHIhWnCD",
        "colab_type": "text"
      },
      "source": [
        "## Filtrando linhas iniciando com datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjDa8T3mJikk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines_by_dates = []\n",
        "\n",
        "for _, line_words in lines.items():\n",
        "  \n",
        "  extracted_date, leading_text = extract_date(line_words)\n",
        "\n",
        "  if extracted_date:\n",
        "    date_index = leading_text.index(str(extracted_date))\n",
        "    symbols = [symbol for word in words for symbol in word.symbols]\n",
        "    date_symbols = symbols[date_index : date_index + len(extracted_date)]\n",
        "    \n",
        "    date_line = {\n",
        "      'text': extracted_date,\n",
        "      'vertices': estimate_word_vertices(date_symbols),\n",
        "      'symbols': date_symbols,\n",
        "      'time_records': []\n",
        "    }\n",
        "    lines_by_dates = lines_by_dates + [(date_line, line_words)]\n",
        "\n",
        "lines_by_dates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3feNYhzEYHZa",
        "colab_type": "text"
      },
      "source": [
        "### Plotando as linhas com datas iniciais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5RU075rPInX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = prepare_image_data(image_data)\n",
        "for\titem_index, line_by_date in enumerate(lines_by_dates):\n",
        "  date = line_by_date[0]\n",
        "  words = line_by_date[1]\n",
        "  for word in words:\n",
        "    plt.title(f'{image_path} date lines')\n",
        "    plot_polygon(ax, word.bounding_box.vertices, color_index= item_index, to_fill= False)\n",
        "    annotate(get_word_text(word), word.bounding_box.vertices[2])\n",
        "\n",
        "plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_YAjB4bZM-s",
        "colab_type": "text"
      },
      "source": [
        "## Preparando código para a identificar o que é data da batida, o que é horário da batida e o que é observação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MKlaw8CZKwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para limpar caracters finais indesejados\n",
        "def rtrip_words(words, tokens_to_strip = TOKENS_TO_STRIP):\n",
        "  result = list(words)\n",
        "  to_examine_ending = any(words)\n",
        "  \n",
        "  while to_examine_ending:\n",
        "    text_to_strip = get_word_text(result[-1])\n",
        "    stripped_text = text_to_strip.rstrip(''.join(TOKENS_TO_STRIP))\n",
        "    \n",
        "    if stripped_text:\n",
        "      to_examine_ending = False\n",
        "      continue\n",
        "      \n",
        "    result = result[:-1]\n",
        "    if not result:\n",
        "      break\n",
        "      \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-yUnwcNZ6hK",
        "colab_type": "text"
      },
      "source": [
        "## Limpando e indexando palavras das linhas iniciadas com datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to9a8qyGaNtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Limpando e indexando palavras das linhas iniciadas com datas\n",
        "words_to_group = []\n",
        "words_to_group_indexes = []\n",
        "\n",
        "for line_by_date in lines_by_dates:\n",
        "  date_line = line_by_date[0]\n",
        "  words = line_by_date[1]\n",
        "\n",
        "  words = rtrip_words(words)\n",
        "\n",
        "  for index, word in enumerate(words):\n",
        "    words_to_group += [word]\n",
        "    words_to_group_indexes += [(date_line, index)]\n",
        "\n",
        "\n",
        "# Encontrando os grupos de palavras com o K-Means\n",
        "k_groups_count = 3 # Date records, Time records, Observations\n",
        "k_means_random_state = 0 # For reproducibility\n",
        "\n",
        "samples = [[word.bounding_box.vertices[0].x,1] for word in words_to_group]\n",
        "labels = KMeans(n_clusters= k_groups_count, random_state= k_means_random_state).fit_predict(samples)\n",
        "\n",
        "\n",
        "# Identificando os labels do grupo das observações\n",
        "positions = [sample[0] for sample in samples]\n",
        "max_position = max(positions)\n",
        "max_position_index = positions.index(max_position)\n",
        "observation_labels = [labels[max_position_index]]\n",
        "\n",
        "\n",
        "# Identificando os labels do grupo da data inicial\n",
        "min_position = min(positions)\n",
        "min_position_index = positions.index(min_position)\n",
        "leading_date_labels = [labels[min_position_index]]\n",
        "\n",
        "\n",
        "# Identificando os índices dos grupos da data inicial e das batidas\n",
        "time_records_indexes = [None if label in observation_labels or label in leading_date_labels else words_to_group_indexes[index] for index, label in enumerate(labels)]\n",
        "time_records_indexes = list(filter(lambda index: index, time_records_indexes))\n",
        "\n",
        "leading_date_indexes = [None if label not in leading_date_labels else words_to_group_indexes[index] for index, label in enumerate(labels)]\n",
        "leading_date_indexes = list(filter(lambda index: index, leading_date_indexes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmXP5RJZkvuk",
        "colab_type": "text"
      },
      "source": [
        "## Filtrando as batidas e associando às datas iniciais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQU-ORFfktxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import statistics\n",
        "\n",
        "\n",
        "# filter words to consider in date_lines\n",
        "for line_by_date in lines_by_dates:\n",
        "  date_line = line_by_date[0]\n",
        "  words = line_by_date[1]\n",
        "\n",
        "  current_date_composite_time_records_indexes = filter(lambda index: index[0] == date_line, time_records_indexes)\n",
        "  current_date_direct_time_records_indexes = [index[1] for index in current_date_composite_time_records_indexes]\n",
        "  time_records_words = [words[index] for index in current_date_direct_time_records_indexes]\n",
        "  # lines_by_dates[line_index] = (lines_by_dates[line_index][0], time_records_words)\n",
        "\n",
        "  current_date_composite_leading_date_indexes = filter(lambda index: index[0] == date_line, leading_date_indexes)\n",
        "  current_date_direct_leading_date_indexes = [index[1] for index in current_date_composite_leading_date_indexes]\n",
        "  leading_date_words = [words[index] for index in current_date_direct_leading_date_indexes]\n",
        "\n",
        "  leading_date_text = ''\n",
        "  for word in leading_date_words:\n",
        "    leading_date_text += get_word_text(word)\n",
        "\n",
        "  if not leading_date_text:\n",
        "    continue\n",
        "\n",
        "  time_records_text = ''\n",
        "  for word in time_records_words:\n",
        "    time_records_text += get_word_text(word)\n",
        "\n",
        "  time_records_symbols = [symbol for word in time_records_words for symbol in word.symbols]\n",
        "\n",
        "  time_records = []\n",
        "  for finding in re.finditer(r'\\d{2}[\\.:]\\d{2}', time_records_text):\n",
        "    ini_index = finding.start()\n",
        "    fim_index = finding.end()\n",
        "    finding_symbols = time_records_symbols[ini_index:fim_index]\n",
        "\n",
        "    finding_text = finding.group(0).replace('.',':')\n",
        "    finding_vertices = estimate_word_vertices(finding_symbols)\n",
        "\n",
        "    time_records += [{\n",
        "      'text': finding_text,\n",
        "      'vertices': finding_vertices,\n",
        "      'symbols': finding_symbols\n",
        "    }]\n",
        "\n",
        "  date_line['time_records'] = time_records\n",
        "\n",
        "lines_by_dates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usc4WOvxYawS",
        "colab_type": "text"
      },
      "source": [
        "### Plotando as batidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccoe5jah9xt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = prepare_image_data(image_data)\n",
        "for\titem_index, line_by_date in enumerate(lines_by_dates):\n",
        "  date = line_by_date[0]\n",
        "  time_records = date['time_records']\n",
        "  for time_record in time_records:\n",
        "    plt.title(f'{image_path} time records')\n",
        "    plot_polygon(ax, time_record['vertices'], color_index= item_index, to_fill= False)\n",
        "    annotate(time_record['text'], time_record['vertices'][2])\n",
        "\n",
        "plot()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}